2025-03-08 23:38:24,662 INFO    MainThread:32324 [wandb_setup.py:_flush():67] Current SDK version is 0.19.7
2025-03-08 23:38:24,662 INFO    MainThread:32324 [wandb_setup.py:_flush():67] Configure stats pid to 32324
2025-03-08 23:38:24,662 INFO    MainThread:32324 [wandb_setup.py:_flush():67] Loading settings from C:\Users\jaygu\.config\wandb\settings
2025-03-08 23:38:24,662 INFO    MainThread:32324 [wandb_setup.py:_flush():67] Loading settings from F:\Semester 8\Introduction to Deep Learning\Assignment_1\wandb\settings
2025-03-08 23:38:24,662 INFO    MainThread:32324 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:setup_run_log_directory():647] Logging user logs to F:\Semester 8\Introduction to Deep Learning\Assignment_1\wandb\run-20250308_233824-4x7miojm\logs\debug.log
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to F:\Semester 8\Introduction to Deep Learning\Assignment_1\wandb\run-20250308_233824-4x7miojm\logs\debug-internal.log
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:init():761] calling init triggers
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:init():766] wandb.init called with sweep_config: {'activation': 'tanh', 'batch_size': 32, 'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 4, 'optimizer': 'momentum', 'weight_decay': 0.0005, 'weight_init': 'xavier_normal'}
config: {'epochs': 5, 'batch_size': 32, 'eval_freq': 1, 'learning_rate': 0.0001, 'dataset': 'fashion_mnist', 'hidden_size': 64, 'num_layers': 4, 'optimizer': 'momentum', 'weight_init': 'xavier_normal', 'activation': 'tanh', 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'momentum': 0.9, 'weight_decay': 0.0005, 'wandb_project': 'Multilayer_FeedForward_Network', 'wandb_entity': 'jay_gupta-indian-institute-of-technology-madras', 'beta': 0.9, 'loss': 'cross_entropy', '_wandb': {}}
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:init():784] starting backend
2025-03-08 23:38:24,663 INFO    MainThread:32324 [wandb_init.py:init():788] sending inform_init request
2025-03-08 23:38:24,680 INFO    MainThread:32324 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=spawn, using: spawn
2025-03-08 23:38:24,681 INFO    MainThread:32324 [wandb_init.py:init():803] backend started and connected
2025-03-08 23:38:24,682 INFO    MainThread:32324 [wandb_run.py:_config_callback():1261] config_cb None None {'activation': 'tanh', 'batch_size': 32, 'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 4, 'optimizer': 'momentum', 'weight_decay': 0.0005, 'weight_init': 'xavier_normal'}
2025-03-08 23:38:24,682 INFO    MainThread:32324 [wandb_init.py:init():896] updated telemetry
2025-03-08 23:38:24,718 INFO    MainThread:32324 [wandb_init.py:init():920] communicating run to backend with 90.0 second timeout
