The training cross entropy loss at epoch 0 is 0.6208545214643767
The training accuracy at epoch 0 is 0.7741224822274881
The training cross entropy loss at epoch 1 is 0.5087746641903684
The training accuracy at epoch 1 is 0.8227006812796208
The training cross entropy loss at epoch 2 is 0.49336974124376337
The training accuracy at epoch 2 is 0.828698904028436
The training cross entropy loss at epoch 3 is 0.503249578488383
The training accuracy at epoch 3 is 0.825681279620853
The training cross entropy loss at epoch 4 is 0.5287616426973529
The training accuracy at epoch 4 is 0.8174800059241706
Traceback (most recent call last):
  File "F:\Semester 8\Introduction to Deep Learning\Assignment_1\train.py", line 44, in <module>
    model.train(train_batches,test_batches,val_batches)
  File "F:\Semester 8\Introduction to Deep Learning\Assignment_1\model.py", line 92, in train
    Y_pred = self.forward(X_batch)  # Perform forward pass
  File "F:\Semester 8\Introduction to Deep Learning\Assignment_1\model.py", line 53, in forward
    Z = layer.forward(A)  # Forward pass through layer
  File "F:\Semester 8\Introduction to Deep Learning\Assignment_1\layer.py", line 77, in forward
    return np.dot(self.weights, x) + self.biases
KeyboardInterrupt
